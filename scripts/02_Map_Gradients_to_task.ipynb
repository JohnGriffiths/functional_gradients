{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Step 2\n",
    "## Match the gradients to working memory task time-series and predict task condition\n",
    "\n",
    "In this step we take use the three non-trivial gradients with highest eigenvalues and match them to task time-series. This will allow us to re-express the task-related BOLD time-series as a time series of gradients. The steps are the following:\n",
    "\n",
    "1. Load single run of task time-series.\n",
    "2. Normalize the task time-series to have mean = 0 and variance = 1 (z-score).\n",
    "3. For each volume independently, compute coefficients of a linear regression model with gradients as predictors.\n",
    "\n",
    "To reproduce the results, you need to provide your own copy of HCP working memory task data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/nibabel/cifti2/parse_cifti2.py:24: FutureWarning: We no longer carry a copy of the 'six' package in nibabel; Please import the 'six' package directly\n",
      "  from ..externals.six import BytesIO\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import h5py as h5\n",
    "import time\n",
    "import os\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from fgrad.regress import regress_subject, trim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    }
   ],
   "source": [
    "gradients = nib.load('../data/rsFC_eigenvectors.dscalar.nii').get_data().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjects = sorted(glob.glob('/Users/marcel/projects/HCP/data/*'))\n",
    "n_sub = len(subjects)\n",
    "n_runs = 2 # maximum number of runs per subject\n",
    "n_grad = 10 # number of gradients to fit\n",
    "n_tp = 405 # maximum number of time points in time series\n",
    "\n",
    "ts_gradients = np.zeros([n_sub, n_runs, n_tp, n_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject /Users/marcel/projects/HCP/data/100307, 1 of 2\n",
      "Found 2 runs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/2 took 5.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pixdim[1,2,3] should be non-zero; setting 0 dims to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2/2 took 5.16 seconds\n",
      "Subject /Users/marcel/projects/HCP/data/666, 2 of 2\n",
      "Found 0 runs\n",
      "Found no runs for subject /Users/marcel/projects/HCP/data/666!\n"
     ]
    }
   ],
   "source": [
    "for j, s in enumerate(subjects):\n",
    "    print \"Subject %s, %d of %d\" % (s, j+1, n_sub)\n",
    "    files = sorted(glob.glob('%s/MNINonLinear/Results/tfMRI_WM_*/tfMRI_*_Atlas_MSMAll.dtseries.nii' % s))\n",
    "    print \"Found %d runs\" % len(files)\n",
    "    if len(files) > 0:\n",
    "        for i, f in enumerate(files):\n",
    "            t = time.time()\n",
    "            ts_gradients[j, i, :, :] = regress_subject(files[0], gradients[:,0:n_grad])\n",
    "            print \"Run %d/%d took %.2f seconds\" % (i+1, len(files), time.time() - t)\n",
    "    else:\n",
    "        print \"Found no runs for subject %s!\" % s\n",
    "\n",
    "ts_gradients, r, subjects = trim_data(ts_gradients, subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('../data/reconstructed_WM.hdf5'):\n",
    "    os.remove('../data/reconstructed_WM.hdf5')\n",
    "\n",
    "f = h5.File('../data/reconstructed_WM.hdf5')\n",
    "g = f.create_group('Working_memory')\n",
    "g.create_dataset('LR', data = ts_gradients[:,0,:,:], compression = \"gzip\", chunks = (1,n_tp,n_grad))\n",
    "g.create_dataset('RL', data = ts_gradients[:,1,:,:], compression = \"gzip\", chunks = (1,n_tp,n_grad))\n",
    "g.create_dataset('Subjects', data = s)\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
